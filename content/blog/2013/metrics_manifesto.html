---
title: The Metrics Manifesto - Why you need a metric
created: !!timestamp '2013-01-15 10:00:00'
tags:
    - metrics
    - data analysis
---

{% mark excerpt -%}

You can't optimize what you can't measure. Except in a few politicized fields such as education, this is a generally accepted truth and is typically too cliched to repeat. But once you decide to measure something it is very important to figure out a good metric. At the end of the day, given a metric `m(d)`, you will make a decision based primarily on the numerical value of `m(d)` - greater than some threshold implies "Go", while below that threshold means "Stop".

If you pick the wrong metric, you'll make the wrong decision, so it's very important to get this right. Your metric is a clear and consistent way of deciding what it is you actually want.

{%- endmark %}

I'll begin by restricting discussion in thie article to metrics which form an *objective function*. In the field of [optimization](https://en.wikipedia.org/wiki/Mathematical_optimization), an *objective function* is a quantity that you wish to maximize. I.e., your goal is to find an objective function `m(x)` such that whenever you choose an `x` which makes `m(x)` larger, the outcome of your organization is improved. I'll use the terms "metric" and "objective function" interchangeably.

For example, at a for-profit company the obvious choice of `m(x)` would be profit, and `x` would be the set of states of the world. The goal is then to choose actions the company can take which will cause the resulting input `x` to maximize `m(x)` (which can be constrained to exclude some actions, such as "don't be evil" in the case of Google).

A picture is worth a thousand words, so here is our first picture:

![An optimization problem](metrics_manifesto/optimization.png)

The `x` axis represents a control variable - think of it as representing a state of the world (e.g., a world in which we give a patient `x` mg of a drug). The `y` value represents our objective function, or how much we value the outcome given a choice of `x`. Given two different values of `x`, we can always choose which one we prefer - we always prefer the `x` value for which the corresponding `y` value is greater.

In practice, we obviously cannot always choose arbitrary `x`. Some world states might be inaccessible - I don't know how to move to a world state where my bank account has $20B in it, for example. Sometimes you don't know which world state your actions will cause you to switch to. These are important issues, but they are a topic for another post. None of these issues change the fact that you need an objective function on world states - they just create further difficulty when you try to optimize it.

**Who should read this:** My original plan was to write a single blog post about how to come up with good metrics. After it swelled to thousands of words, I decided to break it up. This post deals solely with what an objective function is and why you need one. If you are already convinced you should define an objective function and use it to make decisions, skip this post and wait for the next one.

### An example

Consider Steve, a software engineer, who is trying to choose between several jobs.

1. Quantitative Analyst at the Goldberg-Stannis Investment Bank. They pay $200k/year, but the work environment is a cutthroat and political, long hours are required, and the work is only moderately interesting.
2. Data Scientist at Legacy Systems Media Corporation. They pay $150k/year, have a friendly work environment (but with moderate corporate BS), reasonable hours and interesting work.
3. Engineer at Hyperlocal Social Hipster Labs, an early stage startup. They pay $90k/year, have a friendly work environment (no corporate BS), long hours, and interesting work. He also really likes his potential boss.

The first thing Steve should do is figure out his objective function, which is a simple way of asking him to decide what he values in life. The simplest unit in which to measure this is dollars.

Steve is willing to work long hours, but he decides that reasonable hours are worth $20k/year to him. A friendly work environment is very important to him - avoiding politics is worth $15k, and avoiding corporate BS is worth another $5k. Interesting work is worth another $20k to him, and liking his boss is worth $10k. Steve's objective function is therefore:

    m = salary + $20k*(reasonable hours) + $15k*(no politics) + $5k*(no corporate BS)
          + $20k*(interesting work) + $10k*(boss quality)

Using this metric, Steve can now make a decision. The first job is worth $200k to him, the second is worth $150+15+20+20=$205, the third is worth $90+15+5+20+10=$140k.

Constructing the objective function is merely a way for Steve to force himself to decide exactly how much he values both the monetary and non-monetary aspects of his job.

#### But you can't reduce everything to money

You need to reduce everything to a single common value, but using dollars is just an arbitrary choice. We could easily use units of [Utilons](http://wiki.lesswrong.com/wiki/Utility), which (roughly speaking) are increments of happiness. At the simplest level, we could simply declare `$1 = 4 utilons` and express our metric in Utilons, in which case Steve chooses job (2) which gives him 820 utilons.

In some cases this might be a better choice than money, because it enables you to express the law of diminishing marginal returns. Going from $200k/year to $205k/year will not bring you as much happiness as going from $20k/year to $25k/year. If we define our objective function in units of utilons, and choose the value of money to be `10k * sqrt(money/$1000)` (or any function with decreasing first derivative), we can represent this idea quantitatively.

Defining an objective function is not about ignoring non-monetary values. If you do that, you are doing it wrong. Defining an objective function is merely about deciding beforehand how much your non-monetary values are worth - how much of one you are willing to trade for the other, and under what circumstances.

## A metric is equivalent to a consistent decision making process

A common critique of metric-driven decision making is that "you can't reduce the whole world down to a single number". This philosophy is simply incorrect. I will assert that any consistent and complete decision making process is fundamentally identical to a metric.

Suppose you have a  decision making process. What I mean by this is that you can, given any two scenarios, decide which scenario is more desirable. Suppose further that this process is transitive, which means that if A is preferable to B and state B is preferable to C, then A is preferable to C. In that case, you can construct a well defined mapping from world states to numbers  - this is an exercise in elementary topology.

To understand this example, consider a world with three states:

    [A,B,C]

Suppose we consider `C` the best, `B` second best and `A` worst. In that case, a valid metric would be:

    m = { "A" : 1, "B" : 2, "C" : 3 }

Another equally valid metric would be:

    m = { "A" : 100, "B" : 1000000, "C" : 1e27 }

The numbers here don't actually matter - all that matters is the relative ordering.

This vague idea can always be extended. (Skip this paragraph if you find it too mathy.) Consider another element in the state space, perhaps `X`. Consider the set of all elements in state space to which we've already assigned a value, and divide them into elements inferior to `X` (call this set `LT`), and elements superior to `X` (call this set `GT`). Then set the value of `m(X)` equal to `0.5 * ( max(LT) + MIN(GT))`. Apply induction and you find you have a metric on a countably infinite set. (Note that I just used the [axiom of choice](https://en.wikipedia.org/wiki/Axiom_of_choice).) This shows that a consistent decision making process is always equivalent to a metric on countably infinite sets.

The key idea here: an objective function is nothing more than a convenient way to rank which world states you consider more desirable. If you consider Bipasha Basu to be more beautiful than Megan Fox, `m(girlfriend == Bipasha Basu) > m(girlfriend == Megan Fox)`. If you felt the opposite, the inequality should be reversed. Don't be fooled by the presence of mathematics - this is a very simple idea.

### Understand your tradeoffs

The critical part of defining an objective function is figuring out what your tradeoffs are. In an educational setting, we want students to understand both mathematics and English. In a world of limited resources, we cannot improve both of these skills as much a we might like. At some point, we must answer the question: "how much math skill will we give up to gain a unit of English skill?"

If we define the metric as `3 * math + 2 * english` (assuming math and english both vary from 1 to 10), we are explicitly stating that we will give up 3 units of english for every 2 units of math we might gain (or vice versa).

You can't have everything. If you can't define how much you value one goal relative to another, you don't really understand what you want.

## There can be only one

It is a fundamental fact of optimization that you can only have one objective function. You simply cannot simultaneously maximize two different functions, because the maxima of one might not be the maxima of the other. See the following graph:

![Several monotonic functions](metrics_manifesto/two_metrics.png)

This graph demonstrates the problem with having multiple metrics. By choosing `x=3`, we maximize the first one. By choosing `x=7` we maximize the second one. They cannot both be simultaneously maximized.

![Several monotonic functions](metrics_manifesto/two_metrics_combined.png)

Once a set of tradeoffs has been made, a decision is clear.

Coming up with a single, well defined metric is nothing more than the process of thinking clearly and deciding what you want. You don't know what you want until you know your objective function.

## Inconsistent decisionmaking

Suppose you lack a metric, or equivalently a consistent decision making process. What this means is that the decisions you make are not necessarily consistent with each other, and you may become a [Money Pump](http://lesswrong.com/lw/1dr/money_pumping_in_general/?sort=old). A money pump is a theoretical construct by which you make a series of decisions that bring you back to where you started, but slightly poorer than before.

The real life risk of becoming a money pump is low, mainly because it requires a malicious actor to understand and exploit your preferences. However, there is a real life risk that your decisionmaking will be path-dependent.

Consider the following scenario (numerical example shamelessly ripped off from Eliezer Yudkowsky). You must choose between one of the two options:

    A) 34% chance of winning $2,400.
    B) 33% chance of winning $2,700.

Most people will choose option (B), as was demonstrated in an early economics experiment (see Allais, M. (1953). Le comportement de l'homme rationnel devant le risque: Critique des postulats et axiomes de l'ĂŠcole amĂŠricaine. Econometrica, 21, 503-46.).

Now consider the following alternate path, a sequence of two decisions:

    W) Win $24 with certainty.
    X) A 33/34 chance of winning $27.

Most people will choose (W) over (X). After this decision is made, you have the option of betting all your winnings from the previous decision:

    Y) 34% chance of winning $100 for every $1 you put in.
    Z) Don't bet, and keep your money.

Although I have no experimental evidence to back it up, I suspect most people would choose (Y) - your expected return from this gamble is 3,300%.

Here is where things get dicey - choosing (W) and then (Y) is equivalent to choosing (A).

In reality, either situation (A) or (B) is better - for simplicity I'll assume (B). But if you approach this choice via a different decisionmaking path, applying heuristics as you go, you will suboptimally choose (A) at least some of the time.

I.e., if your decisionmaking is inconsistent, it must be wrong at least some of the time.

Without getting into too much math, it is impossible for us to get into this situation if our decisions are driven by an objective function. Our objective function cares only about the state of the world, and not what choices you made to get there - i.e., `m(A) = m(W -> Y)`, and `m(B) = m(X -> Y)`. Thus, if we consider `m(A) > m(B)`, we will also consider `m(W -> Y) > m(X -> Y)`, and vice versa if `m(B) > m(A)`. See [here](http://lesswrong.com/lw/my/the_allais_paradox/) and [here](http://lesswrong.com/lw/1dr/money_pumping_in_general/?sort=old) for more details.

## Conclusion

The world is too complicated to reduce to a single number - this claim is not in dispute. Defining an objective function is not about reducing the world to a single number. It's about reducing your *decision process* to a single function (of potentially many inputs). It's nothing more than a way to keep yourself honest and consistent. It is only the first step in making good decisions, but it's an essential one.

In future posts I'll describe the properties of a good metric.
