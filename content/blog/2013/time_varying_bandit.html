---
title: Bandit Algorithms when the Conversion Rate Changes
created: !!timestamp '2013-11-11 08:00:00'
tags:
    - statistics
    - bayesian reasoning
    - bandit algorithms
---

{% mark excerpt -%}

As the owner of the spamblog [http://www.iwishiwastaller.com](http://www.iwishiwastaller.com), I've run into the following problem. I'm selling some height enhancing pills full of organic free range snake oil. I've come up with several different calls to action:

* Tired of finding pants that fit? Click here for the solution.
* Click here if you find airplane seats too comfortable.
* The NBA hates him! Click here to learn *one weird trick* for becoming taller!

For obvious reasons, my first thought was to try an A/B test to figure out the best one. It gave me an answer - "one weird trick" was the winner. But just out of curiosity, I ran the test again the next day and discovered that "Tired of finding pants that fit" was the winner. Curious now, I repeated my test several more times, and discovered that the best version changed over time!

This is a problem. A/B testing cannot give me the best solution. Neither can most traditional bandit algorithms. So I decided I had to cook up my own.

{%- endmark %}

One of the major assumptions made by bandit algorithms is that the conversion rate does not vary with time. A/B tests are a little more robust, and allow conversion rates to vary with time *provided one version maintains it's superiority*. In the situation I describe above, A/B tests fail just as surely as any other bandit algorithm which assumes conversion rates maintain their ordering.

In this blog post I'll provide a method that handles the case when conversion rates vary with time according to a certain mathematically tractable random walk. The general strategy follows the [Bayesian Bandit](/blog/2013/bayesian_bandit.html) approach I've described before, but we need to make some forays into PDEs to reach that point.

## The Model

To begin with I'll focus solely on a single conversion rate. Call this rate $@X=X_t$@, where $@t$@ is time. The value $@X_t$@ denotes the probability that at time $@t$@, a given call to action will result in a conversion.

I will assume that the conversion rate $@X_t$@ follows a random walk. For mathematical simplicity I'll choose a standard model called Jacobi Diffusion.

We need to construct a random walk model for $@X_t$@ which ensures that $@X_t$@ remains in $@[0,1]$@. Fortunately there is a standard model of this nature, namely Jacobi Diffusion. I'll be following the analysis of section 2.4 of [this paper](http://www.stt.msu.edu/~mcubed/LMS.pdf), so to begin define $@ Z_t = 2 X_t-1$@. Jacobi diffusion for $@ Z_t $@ takes the form:

$$ d Z_t = - \theta \left(Z_t - \frac{b-a}{a+b+2} \right) dt + \sqrt{ \frac{2 \theta}{a+b+2} (1-Z_t^2) } dW_t $$

where $@dW_t$@ is a Gaussian random walk.

This transformation is done at the start simply to avoid a lot of annoying calculations down the line. This is equivalent to:

$$ 2 d x_t = - \theta \left((2 X_t-1) - \frac{a-b}{a+b+2} \right) dt + \sqrt{ \frac{\theta}{2(a+b+2)} X_t(1-X_t) } dW_t $$

This is a fairly common model in the financial world and is used for modelling interest rates. To get a picture of what this equation means, I'll plot 3 different trajectories for this model, with $@a=0,b=3$@:

![random walk](time_varying_bandit/random_walk.png)

All three trajectories started at CTR=0.6. They stayed in this neighborhood for a short time, but then their random motion caused the information we had to be lost.

The plan going forward is to use the [Bayesian Bandit](bayesian_bandit.html) approach to construct a bandit algorithm, so we wish to derive a probability distribution for $@ X_t $@ at some future time given a value (or distribution) of $@ X_t $@ now. We will use [Ito's Lemma](https://en.wikipedia.org/wiki/It%C5%8D's_lemma), a common technique in mathematical finance. This will allow us to derive a a [Fokker-Planck equation](https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation) from the equation of the random walk. For thos familiar with the methodology, this is exactly how [Black-Scholes](https://en.wikipedia.org/wiki/Black%E2%80%93Scholes) is derived.

The reason we do this is to derive an equation governing the function $@f(z,t)$@, which represents the probability density of $@ Z_t $@ given a specific time.

I'm going to skip the arithmetic details, and just jump straight to the relevant Fokker-Planck Partial Differential equation (PDE):

$$ \frac{\partial f(z,t) }{\partial t} = \frac{\partial }{\partial z} \theta \left[ z - \frac{b-a}{a+b+2} \right] f(z,t) + \frac{\partial^2 }{\partial z ^2} \sigma \sqrt{1-z^2} f(z,t)$$

for

$$ \sigma^2 = \frac{ \theta }{ 2(a+b+2) } $$

The underlying function $@f(z,t)$@ is the probability distribution representing the uncertainty at time $@t$@. I.e., if we plug in a specific value of $@ t$@ - say $@ t=2 $@, then $@ f(z,2) = P(Z=z | t=2)$@ is the probability density for the variable $@Z_2$@.

So we use this function for computing a posterior as follows. Suppose at time $@ t=0 $@ we have some distribution on $@ z $@, call it $@ p_0(z) $@. For example, suppose at exactly $@ t=0 $@, we showed the call to action to 40 people. At this time, there were 14 clicks. We then computed a posterior $@ p_0(z) $@ based on the techniques in [this blog post](bayesian_analysis_conversion_rates.html).

Now suppose we've waited until $@ t = 0.2 $@. We want to know the posterior *now*, which is not the same as the posterior at $@ t=0 $@. So we do the following. We solve the Fokker-Planck equation for $@ f(z,0.2) $@ with $@ f(z,0) = p_0(z) $@, and this represents our new posterior.

I'm not actually going to describe how to solve this PDE right now (hint: Fourier came up with *One Weird Trick*, use that and [Sturm-Liouville theory](https://en.wikipedia.org/wiki/Sturm%E2%80%93Liouville_theory), noting that it's a Jacobi Equation). Instead I'm simply going to discuss the important components of the solution.

### Stationary Distribution

The first important fact to recognize is that this model has a stationary solution corresponding to $@n=0$@:

$$ q_0(x) = \textrm{const}(1-x)^a x^b$$

This is a beta distribution with parameters $@(a,b)$@. This means that if our prior modelled by $@q_0(x)$@, it will remain $@q_0(x)$@ forever.

This stationary solution gives a great method of checking whether I screwed up my calculations somewhere (e.g., flipping a minus sign, losing a factor of 2). We can start with our random walk model, and use a numerical integrator to solve it:

    gaussian_var = norm()
    def dW(dt):
        return norm.rvs() / sqrt(dt)

    def random_walk(z0, tmax, dt, times = None):
        def rhs(z,t):
            return -theta*(z-(a-b)/(a+b+2)) + sqrt(2*theta*(1-z*z)/(a+b+2))*dW(dt)
        if (times is None):
            times = arange(0,tmax,dt)
        z = zeros(shape=times.shape, dtype=float)
        z[0] = z0
        for i in range(1,z.shape[0]):
            z[i] = z[i-1] + rhs(z[i-1], times[i])*dt
            if abs(z[i]) > 1:
                z[i] = z[i] / abs(z[i])
        return (times, z)

Then we can run the simulation many times, and save the value `z` at the end of the simulation. If we choose `tmax` to be sufficiently large, the distribution of these values should approach the stationary solution of the PDE. So if we fit a beta distribution to that data, it should agree with the theoretical result.

I did this, and plotted the result below. The first plot is a histogram of the terminal positions of `z`, while the second is the best fit and theoretical distributions:

![long_term_random_walk_result](time_varying_bandit/long_term_random_walk_result.png)

The result is imperfect due to sampling, but it appears more or less correct. To be precise, it's correct the second time I tried - the first version of my math did make a stupid calculation mistake (lost a factor of 2 somewhere), which this method revealed.

### Behavior of the solution

The second important fact to understand is the solution is dissipative. What this means is that we lose information with time. If we start with a very sharp probability distribution, after some time that solution will spread out and our uncertainty will increase.

I've plotted here the solution of the PDE for a fairly sharp initial condition. At `time=0`, we are extremely confident that the CTR is somewhere between [0.25, 0.45]. At the end of the simulation, all we can say is that it's located somewhere in [0.05, 0.40]. Due to the random walk, our knowledge becomes stale with time.

![dissipative solution](time_varying_bandit/probability_density_random_walk.png)

The black lines are 3 examples of a random walk superimposed on the plot of the density.

Another way to visualize the data is to simply plot the value of $@ f(z,t) $@ for various specific times $@ t $@. Our confidence about what the CTR is is decreasing over time.

![dissipative solution](time_varying_bandit/probability_dist_various_times.png)

## Computing a posterior on $@x$@

Now lets suppose that at time $@ t=0.2 $@, we computed a posterior $@ f(x, 0.2) $@. Suppose that at this time we display the given call to action to some specific user. If a conversion occurs, we can compute the posterior:

$$ \textrm{posterior}(x) = \frac{ x f(x, 0.2) } { \int x f(x, 0.2) dx } $$

Conversely, if no conversion occurred, the posterior would be:

$$ \textrm{posterior}(x) = \frac{ (1-x) f(x, 0.2) } { \int (1-x) f(x, 0.2) dx } $$

Now the question arises - what information do we have at time $@ t=0.3 $@? At time $@ t = 0.2 $@, we know that the CTR is distributed according to $@ \textrm{posterior}(x) $@. So to figure out what we know about the distribution of the CTR at $@ t=0.3 $@, we solve the PDE again. But this time, we take $@ f(x, 0.2) = \textrm{posterior}(x) $@ as our initial condition, and solve the equation for an additional $@ 0.1 $@ seconds into the future (from $@ t=0.2 $@ to $@t=0.3$@).

## The Bayesian Bandit

Now we have a method, albeit a somewhat involved one, for computing the posterior distribution on a *changing variable* based on a sequence of observations. The uncertainty in the posterior distribution now comes from two sources - experimental error during our measurements, and the possibility that the variable changed between the measurements and the present. But this is ok - conceptually, the posterior still represents our uncertainty as to what the true conversion rate is.

We'll now use these posterior distributions and apply the [Bayesian Bandit](/blog/2013/bayesian_bandit.html) technique.

So suppose that for each call to action, we have computed a posterior distribution on it $@ f_1(x,t) $@, $@ f_2(x,t)$@, etc. Now at time $@ t=0.5$@ a user has clicked on the site. We need to figure out which call to action to display to him. The algorithm consists of drawing a sample $@ x_1 $@ from $@ f_1(x,0.5)$@, $@ x_2 $@ from $@ f_2(x,0.5) $@, etc. We then figure out which one is the largest and display that call to action to the user.

After the user has either clicked or not clicked, we then update that particular probability distribution as necessary, just as described in the previous section.

## Other relevant work

The paper [A stochastic diffusion process for the Dirichlet Equation](http://arxiv.org/pdf/1303.0217.pdf) does something similar, but for the Dirichlet Distribution rather than the Beta Distribution. Could come in handy if you need to bucket into more than 2 categories (e.g., `[ NoConvert, ConvertToX, ConvertToY]`).

Also relevant is [The Pearson diffusions: A class of statistically tractable diffusion processes](http://www.econ.au.dk/fileadmin/site_files/filer_oekonomi/Working_Papers/CREATES/2007/rp07_28.pdf) and [On Properties of Analytically Solvable Families of Local Volatility Diffusion Models](http://www.wlu.ca/documents/44066/solvmod.pdf).

I imagine there is more out there in the literature than this. But I've never been much good at literature searches, and most of it is probably behind an academic paywall anyway. But if anyone has pointers, I'd love to see them.

## Appendix: Solving the PDE


It turns out (yay [Sturm-Liouville theory](https://en.wikipedia.org/wiki/Sturm%E2%80%93Liouville_theory)) that this sort of PDE has a fairly straightforward method of solution. Suppose we find an eigenfunction of the right hand side, i.e.:

$$ \frac{\partial }{\partial z} \theta \left[ z - \frac{b-a}{a+b+2} \right] f(z) + \frac{\partial^2 }{\partial z ^2} \sigma \sqrt{1-z^2} f(z) = -\lambda f(z)$$

(This equation is called the eigenvalue equation.)

Then the function

$$ f(z,t) = \exp(-\lambda t) f(z) $$

is a solution of the partial differential equation. More general solutions can be found by computing sums of such solutions.

As luck would have it, rather than doing a bunch of work, we can actually just consult Wikipedia and discover that [Jacobi Polynomials](https://en.wikipedia.org/wiki/Jacobi_polynomials) are the solution to the eigenvalue equation. Specifically,

$$ q_n(z) = (1-z)^b (1+z)^a P^{(b,a)}_n (z) \frac{2n+a+b+1}{2^{(a+b+1)}} \frac{\Gamma(n+1)\Gamma(n+a+b+1)}{\Gamma(n+a+1)\Gamma(n+b+1)} \frac{\Gamma(a+b+2)}{\Gamma(b+1)\Gamma(a+1) 2^{a+b+1}}$$

form a set of eigenvectors with corresponding eigenvalues

$$ \lambda_n = \frac{\theta n(n+a+b+1)}{a+b+2} $$

for $@n=0,1,2,\ldots$@.

Everything I've done here is sketchy, but it is proven in the paper [Fractional Pearson Diffusions](http://www.stt.msu.edu/~mcubed/LMS.pdf) that if a strong solution exists, it is given by:

$$ f(z,t) = \sum_{n=0}^{\infty} f_n e^{-\lambda_n t} q_n(z) $$

We can also rewrite the eigenfunctions in terms of $@x$@ as:

$$ q_n(x) = (1-x)^b x^a P^{(b,a)}_n (2x-1) \frac{2n+a+b+1}{2} \frac{\Gamma(n+1)\Gamma(n+a+b+1)}{\Gamma(n+a+1)\Gamma(n+b+1)} \frac{\Gamma(a+b+2)}{\Gamma(b+1)\Gamma(a+1) 2^{a+b+1}}$$

For more information on using eigenvalue/eigenvectors (aka [spectral methods](https://en.wikipedia.org/wiki/Spectral_method)) to solve partial differential equations, I highly recommend the book [Chebyshev and Fourier Spectral Methods](http://www.amazon.com/gp/product/0486411834/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0486411834&linkCode=as2&tag=christuc-20) by John Boyd.

If $@f(x)$@ were comprised of Jacobi polynomials, we can make use of the following recurrence relation:

$$ A_n
 P^{(a,b)}_{n+1}(z)
 = B_n
 [C_n z + D]
 P^{(a,b)}_n (z)
- [E_n]
P{n-1}^{(a,b)}(z)
$$

$$ A_n=2(n+1)(n+a+b+1)(2n+a+b) $$

$$ B_n = (2n+a+b+1) $$

$$ C_n=(2n+a+b+2)(2n+a+b) $$

$$ D = a^2-b^2 $$

$$ E_n = 2(n+a)(n+b)(2n+a+b+2)$$

Rearranging and substituting $@2x-1$@ for $@z$@ yields:

$$ x P_n^{(a,b)}(2x-1) = \frac{1}{2C_n} \left[
\frac{A_n}{B_n}P_{n+1}^{(a,b)}(2x-1)
-(D-2C_n) P^{(a,b)}_n (z)
+\frac{E_n}{B_n}P_n-1^{(a,b)}(z)
\right]$$

Computing $@(1-x) P_n^{(a,b)}(2x-1)$@ can be done in the same way.

So if we represent our prior $@f(x)$@ in terms of Eigenfunctions, i.e.

$$ f(x) = \sum_{n=0}^{\infty} f_n q_n(2x-1) $$

then computing a posterior is a matter of multiplying the vector $@[f_0, f_1, ..., f_n]^T$@ by a [tri-diagonal matrix](https://en.wikipedia.org/wiki/Tridiagonal_matrix) followed by a normalization step. Let us let $@X$@ denote that matrix.

Similarly, let $@U(t)=\textrm{diag}[e^{-\lambda_0 t}, e^{-\lambda_1 t}, \ldots, e^{-\lambda_n t}]$@ denote the time evolution operator of solutions to the random walk itself.


### Appendix: An algorithm for computing the posterior

Suppose now we run a sequence of experiments, $@S_0, S_1, ..., S_n$@ at times $@ t_0 < t_1 < \ldots < t_n$@. Suppose for simplicity we take as our prior $@\vec{f}_0 = [1, 0, 0, \ldots]$@. At time $@t_0 + \delta$@, we can compute the posterior:

$$ \vec{f}(t_0+\delta) = \textrm{normalize} \left[ U(\delta) S_0 U(t_0) \vec{f}_0 \right] $$

where $@S_0=X$@ if the experiment $@S_0$@ resulted in a conversion, and $@S_0=(1-X)$@ otherwise.

Similarly, at $@t_1+\delta$@ we obtain:

$$ \vec{f}(t_1+\delta) = \textrm{normalize}  \left[  U(\delta)S_1 U(t_1-t_0) S_0 U(t_0) \vec{f}_0 \right] $$

Computing the posterior at various future points is the same process, repeated ad nauseum.
